# Multi-Agent Infrastructure - LLM API Keys Configuration
# Copy this file to .env and fill in your API keys
# The system will automatically load keys from .env file

# =============================================================================
# Default LLM Configuration
# Set the provider and model to use by default
# Available providers: openai, anthropic, google, cohere, groq, moonshot, openrouter, ollama, azure
# =============================================================================
LLM_PROVIDER=openai
LLM_MODEL=gpt-4o-mini

# =============================================================================
# OpenAI - GPT-4o, GPT-4o-mini, GPT-4, o1 models
# Get your key at: https://platform.openai.com/api-keys
# =============================================================================
OPENAI_API_KEY=sk-your-openai-api-key-here

# =============================================================================
# Anthropic - Claude 3.5 Sonnet, Claude 3 Opus, Claude 3 Haiku
# Get your key at: https://console.anthropic.com/
# =============================================================================
ANTHROPIC_API_KEY=sk-ant-your-anthropic-api-key-here

# =============================================================================
# Google - Gemini 1.5 Flash, Gemini 1.5 Pro
# Get your key at: https://ai.google.dev/
# =============================================================================
GOOGLE_API_KEY=your-google-api-key-here

# =============================================================================
# Cohere - Command R, Command R+
# Get your key at: https://dashboard.cohere.com/api-keys
# =============================================================================
COHERE_API_KEY=your-cohere-api-key-here

# =============================================================================
# Groq - Llama 3.3, Mixtral, Gemma (very fast inference)
# Get your key at: https://console.groq.com/keys
# =============================================================================
GROQ_API_KEY=gsk-your-groq-api-key-here

# =============================================================================
# Moonshot AI - Kimi k2.5, Kimi k1.5 (Strong Chinese & English capabilities)
# Get your key at: https://platform.moonshot.cn/
# =============================================================================
MOONSHOT_API_KEY=sk-your-moonshot-api-key-here

# =============================================================================
# OpenRouter - Access to 200+ models via unified API
# Including: Claude, GPT, Llama, Mistral, DeepSeek, Qwen, and more
# Get your key at: https://openrouter.ai/keys
# =============================================================================
OPENROUTER_API_KEY=sk-or-v1-your-openrouter-api-key-here

# =============================================================================
# Azure OpenAI (optional)
# =============================================================================
# AZURE_OPENAI_API_KEY=your-azure-openai-api-key
# AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
# OPENAI_API_VERSION=2024-02-15-preview

# =============================================================================
# Ollama (local models - no API key needed)
# Make sure Ollama is running locally: http://localhost:11434
# =============================================================================
# OLLAMA_BASE_URL=http://localhost:11434

# =============================================================================
# Rate Limiting Configuration (Recommended for Google Gemini)
# =============================================================================
# Enable rate limiting globally
ENABLE_RATE_LIMITING=true

# Default rate limit settings (applies to all providers unless overridden)
# RATE_LIMIT_REQUESTS_PER_SECOND=1.0
# RATE_LIMIT_CHECK_EVERY_N_SECONDS=0.1
# RATE_LIMIT_MAX_BUCKET_SIZE=10.0

# Provider-specific rate limit settings (overrides defaults)
GOOGLE_RATE_LIMIT_RPS=0.7          # Gemini: 60 requests/minute on free tier
OPENAI_RATE_LIMIT_RPS=50.0         # OpenAI: High limit, usually not needed
ANTHROPIC_RATE_LIMIT_RPS=10.0      # Anthropic: Depends on tier
MOONSHOT_RATE_LIMIT_RPS=2.0        # Moonshot AI
GROQ_RATE_LIMIT_RPS=30.0           # Groq: Very high limits
COHERE_RATE_LIMIT_RPS=5.0          # Cohere
OPENROUTER_RATE_LIMIT_RPS=1.0    # OpenRouter

# Disable rate limiting for specific providers (set to true to disable)
DISABLE_RATE_LIMITING_GOOGLE=false
DISABLE_RATE_LIMITING_OPENAI=true
DISABLE_RATE_LIMITING_ANTHROPIC=false
